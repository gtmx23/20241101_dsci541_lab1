{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 541 Lab 1 - Disinformation and metrics\n",
    "\n",
    "## Required readings\n",
    "\n",
    "We will cover most of these videos during lecture time (I have indicated which ones below), but I am including them all here so that you have everything in one place. In the lab, there might be questions on specifics from the required readings whereas the optional readings are more of a general help and for your own interest.\n",
    "\n",
    "- **Lec 1** Renee DiResta [\"How do we know what's true anymore\"](https://www.youtube.com/watch?v=vIkJoUeoY-o)\n",
    "- **Lec 2 (partly)** Rachel Thomas [\"Disinformation\"](https://www.youtube.com/watch?v=eFjk79ykWZk&t=1971s) (32:51 - 1:26:00)\n",
    "- [PBS Facebook documentary](https://www.youtube.com/watch?v=Lg4XW4c9AAc) (1 h video. [Link if you're in the US](https://www.youtube.com/watch?v=EuA4qxPbpQE))\n",
    "- [A framework for ethical decision making](https://www.brown.edu/academics/science-and-technology-studies/framework-making-ethical-decisions) (15 min read, skip the entire section \"2. Traditional arrangement of the field of ethics\")\n",
    "- Rachel Thomas [\"The Problem with Metrics\"](https://www.fast.ai/2019/09/24/metrics/) (10 min read. There is also [a video on the same topic](https://youtu.be/US42H1znvKU?t=39), but this is more similar to what we covered in class already)\n",
    "- Guillaume Chaslot  [\"How Algorithms Can Learn to Discredit 'the Media'\"](https://guillaumechaslot.medium.com/how-algorithms-can-learn-to-discredit-the-media-d1360157c4fa)(5 min read. Chaslot formerly worked at YouTube and founder of [algotransparency](https://www.algotransparency.org)).\n",
    "\n",
    "## Optional readings\n",
    "\n",
    "<details><summary>Click to show</summary>\n",
    "\n",
    "You don't have to read these before lab and you don't have to read all of them. The main reason for including them here is as a recommendation of where to deepen your knowledge if there is something that you find particularly interesting. I am giving a brief background to each so you can pick the ones that peak your interest.\n",
    "\n",
    "- Rachel Thomas [\"Disinformation\"](https://www.youtube.com/watch?v=eFjk79ykWZk&t=867s) (14:27 - 32:51).\n",
    "    - This is similar to Renee DiResta's talk we watch the first lecture, but goes through additional examples including a bit more on bias which we will talk about in later weeks.\n",
    "- Will Oremus [\"The Simplest Way to Spot Coronavirus Misinformation on Social Media\"](https://onezero.medium.com/the-simplest-way-to-spot-coronavirus-misinformation-on-social-media-4b7995448071)\n",
    "    - [Will Oremus](https://medium.com/@WillOremus) is a writer on digital literacy at Medium. This post covers how COVID mis & disinformation has been spread on social media and summarizes a few resources for steps you can take to quickly assess if something is likely true or not.\n",
    "- Rachelle Hampton [\"The Black Feminists Who Saw the Alt-Right Threat Coming\"](https://slate.com/technology/2019/04/black-feminists-alt-right-twitter-gamergate.html)\n",
    "    - [Rachelle Hampton](https://muckrack.com/rachelle-hampton) is a culture writer and reporter at Slate. This post covers how fake twitter accounts were put up in an attempt to stir up negative emotions around the black feminist community on Twitter and the real world consequences that followed. It also goes into how such behavior has been observed in other similar instances and the sources it sprung from.\n",
    "- This last one will not be accessible to all so its official classification is \"very optional\", but if you have access to watch Black Mirror (e.g. on Netflix), I recommend the episode \"The Waldo Moment\". It posits truth against popularity in a local election and shows how spreading disinformation can gain people's support when there is a lack of critical thinking and general fatigue with the current status. The instigator is a savage digital teddybear running for office which as you can hear already makes for a worthwhile watch.\n",
    "</details>\n",
    "\n",
    "### Optional deepfake readings\n",
    "\n",
    "<details><summary>Click to show</summary>\n",
    "Since we don't have time to cover this much in class, I put together some resources on deepfakes. As these are becoming rather prevalent, I urge you to watch at least the first video here (~8 min) for you own digital health. A general disclaimer about the other content below is that some of it can be a bit uncanny with a slight dystopian vibe to it, so view at your own discretion (I think it is better to include this type of content as optional and let you decide what to watch, so that you can be aware of it and its individual/societal impact rather than that I don't mention it at all)\n",
    "\n",
    "- [This is a good introduction to deepfakes anchored in a current event from a few weeks ago.](https://www.youtube.com/watch?v=70l8LzBpGWs)\n",
    "    - A couple of other great quality deepfakes are [this now classic obama interview](https://www.youtube.com/watch?v=cQ54GDm1eL0), this [parody roundtable discussion with celebrities](https://www.youtube.com/watch?v=l_6Tumd8EQI) (disclaimer: sometimes not so appropriate jokes), this [paper review of how to deepfake voices](https://www.youtube.com/watch?v=VQgYPv8tb6A), and this [brief report including how to detect deepfakes](https://www.youtube.com/watch?v=4YpoYvhVmDw) (there are many more deepfakes videos out there).\n",
    "- The input required to make simpler deepfakes is often just a single photo. This is leveraged by MyHeritage, a company for building family trees online that now offers to [animate photos of your deceased relatives through their Deep Nostaliga algorithm](https://www.myheritage.com/deep-nostalgia). Creepy and uncanny? Or just the future you have been waiting for since the first time you read Harry Potter?\n",
    "    - [Emotional video on people watching their relatives \"brought back to life\" with Deep Nostalgia](https://www.youtube.com/watch?v=XqMJm4Gdus0) (viewer discretion advised, included to illustrate just how impactful these services can be and how sophisticated technology can integrate with and speak to what we might think of as very \"human\" emotions).\n",
    "    -  I recommend watching the black mirror episode \"Be right back\" for an extension of this concept to three dimensions.\n",
    "    - [I really recommend the (publicly available) short story \"Thoughts and prayers\"](https://slate.com/technology/2019/01/thoughts-and-prayers-ken-liu-short-story.html) from Ken Liu on what goes wrong when a family agrees to create a digital reanimation of their daughter to raise awareness of the mass-shooting that caused her death (if you like this one, check out his books \"The paper menagerie and other short stories\" and \"The hidden girl and other short stories\").\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission instructions\n",
    "rubric={mechanics:20}\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "<p>You receive marks for submitting your lab correctly, please follow these instructions:</p>\n",
    "\n",
    "<ul>\n",
    "  <li><a href=\"https://ubc-mds.github.io/resources_pages/general_lab_instructions/\">\n",
    "      Follow the general lab instructions.</a></li>\n",
    "  <li><a href=\"https://github.com/UBC-MDS/public/tree/master/rubric\">\n",
    "      Click here to view a description of the rubrics used to grade the questions</a></li>\n",
    "  <li>Push your <code>.ipynb</code> file to your GitHub repository for this lab (make at least three commits).</li>\n",
    "  <li>Upload your <code>.ipynb</code> file to Gradescope.\n",
    "  </li>\n",
    "  <li>Include a clickable link to your GitHub repo for the lab just below this cell\n",
    "    <ul>\n",
    "      <li>It should look something like this https://github.ubc.ca/MDS-2022-23/DSCI_541_labX_yourcwl.</li>\n",
    "      <li>If you are working in a group, you can create you own (public) repo in <a href=\"https://github.ubc.ca/MDS-2023-24\"> the UBC-MDS organization</a> and link that instead.</li>\n",
    "    </ul>\n",
    "  </li>\n",
    "<li>All your written answers must be in your own words.</li>\n",
    "<li>You are not allowed to use generative AI tools to write your answers for you or simply paraphrase answer that you generate from these tools (that will lead to a failing grade), but you can use them to further understand the topics you are learning about.</li>\n",
    " \n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/gtmx23/20241101_dsci541_lab1.git "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall writing quality\n",
    "rubric={writing:20}\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "<p>You will receive an overall writing grade for the entire lab instead of for each question. This is just a small part of your total grade, but please use the Jupyter Lab spell checker extension to catch typos and read through your text for grammatical errors before submitting (or paste it into Google Docs/MS Word/Grammarly. You don't need to type anything under this cell, it is just a placeholder to generate the grading rubric.</p>\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Short answer questions\n",
    "\n",
    "Keep your replies brief, 1-3 sentences per question. Although these are short answer questions, don't copy answers from the readings, use your own words so that you practice learning these concepts. These will not be discussed during the lab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1.1\n",
    "rubric={reasoning:60}\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "<ol type=\"1\">\n",
    "<li>What is the difference between misinformation and disinformation?</li>\n",
    "<li>Disinformation campaigns are not necessarily trying to push a particular political agenda. What is one general goal of these campaigns and how do they try to achieve it?</li>\n",
    "<li>What is an online echo chamber?</li>\n",
    "<li>What are deepfakes and GPT-2/3/4?</li>\n",
    "<li>What is meant with the statement \"If you can make it trend, you can make it true\"?</li>\n",
    "<li>What does Goodhart's law state? Give one example of a how this law might play out in a real life situation (could be a hypothetical or real example).</li>\n",
    "</ol>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR ANSWERS HERE\n",
    "\n",
    "1. The difference between misinformation and disinformation is that misinformation is simply false information, and may not necessarily be targeted or have a negative intention, such as an intent to cause harm. On the other hand, disinformation is often targeted at another group, and is intended to mislead audiences.\n",
    "\n",
    "2. While disinformation campaigns can take various forms, one general goal is to often cause confusion and tension in the general public, sometimes even a targeted population or community. This is often achieved by creating divisions by amplifying divisive issues, undermining trust by spreading misleading information or by trying to manipulate public opinion.\n",
    "\n",
    "3. Online echo chamber refers to a situation in which individuals (or groups) engage in conversations and share perspectives that amplify their personal beliefs, while excluding marginalized or opposing viewpoints. This is often facilitated by social media, whose algorithm is intended to help engage with like-minded individuals.\n",
    "\n",
    "4. Deepfakes are artificial media that is created using deep learning techniques, to manipulate or replace existing content. These medias, created by generative models are often so well created that it is almost impossible to distinguish a deepfake from a real media. Due to this reason, deepfakes are very harmful to exist on the free internet. GPTs are a series of language transformer models. Each version of GPT is trained to generate human-like text based on the input it receives.\n",
    "\n",
    "5. This statement refers to the idea that in this era of social media and fact-paced, engaging content,the popularity of information can influence its perceived truthfulness. In other words, the sheer amount of likes, shares and comments can create an illusion of credibility, even if the information itself is misleading.\n",
    "\n",
    "6.Goodhart's law states that: \"When a measure becomes a target, it ceases to be a good measure\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Discussion questions\n",
    "\n",
    "This section asks you to expand a bit on your reasoning, but still aim to write succinct replies around one paragraph per sub-question. The goal of lab discussions are not to provide you with the right answers, but to help your discussion along. Your TA will assist in this by bringing up topics that you might not have thought of, ask questions to break the silence or a dead end, and move the conversation along so that you have time to go through most questions. How useful the lab discussion is for your submission ultimately relies on that you actively contribute to the discussion and help your peers contribute and exchange ideas.\n",
    "\n",
    "##  Some tips to make your discussions in lab more effective\n",
    "\n",
    "It is easy to overlook the flaws of our own reasoning,\n",
    "so having a discussion with colleagues is an excellent opportunity\n",
    "to develop your thinking and receive feedback\n",
    "from someone who can provide an alternative perspective from your own.\n",
    "Nevertheless,\n",
    "many people don't know how to have an effective discussion,\n",
    "so I am sharing a few tips for you to be able to make the most out of this opportunity:\n",
    "\n",
    "- Commit to learning, not \"winning\" debates. \n",
    "- Comment in order to share information and develop arguments further, not to persuade.\n",
    "- Listen respectfully, without interrupting, to try to understand each others' views.\n",
    "    - Don't focus on what you are going to say next while someone else is talking.\n",
    "- Challenge ideas, not individuals.\n",
    "    - And be open to having your own ideas challenged.\n",
    "- Think about as good arguments as possible against your position.\n",
    "    - This is especially useful if many of your peers have the same opinion, help your group find angles that you might otherwise be missing.\n",
    "- Allow everyone the chance to speak.\n",
    "    - Politely ask members of your group about their opinion.\n",
    "- Avoid assumptions about any member of the class or generalizations about social groups.\n",
    "    - Be careful about asking individuals to speak on the behalf of their (perceived) social group.\n",
    "- Be aware of [logical fallacies](https://blog.hubspot.com/marketing/common-logical-fallacies), but avoid pointing them out in rude or disrespectful ways."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.1 -- Social media responsibilities\n",
    "rubric={reasoning:100}\n",
    "    \n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "<ol>\n",
    "<li>Are social media platforms with the ability to tailor the \"front page/news feed\" for each user (e.g.Â Facebook, Twitter, and YouTube) responsible for the content that they recommend? Should they have the same editorial duties as a news network or are they more like a kiosk selling newspapers?</li>\n",
    "<li>Is it wrong by the social media platform to label some stories as \"fake news\" and some stories as real news? Why should they have the right to perform this censorship? Isn't the best remedy to fake stories to let them be heard and discussed so that everyone can see that they are fake?</li>\n",
    "<li>Write down two or three arguments against your stance on either bullet point 1 or 2 above. Try to make them as strong as possible. Can you understand how some might value these argument higher than the ones you wrote down or do you think this is a clear cut issue without any strong argument against your position?</li>\n",
    "</ol>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.  \n",
    "\n",
    "2.\n",
    "\n",
    "3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.2 -- Metric based engagement\n",
    "rubric={reasoning:100}\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    " \n",
    "<ol type=\"1\">\n",
    "<li>Do you think it is unethical to build an online platform using engagement as the main metric? Don't we want our platforms to be engaging?</li>\n",
    "<li>What are some strategies for using metrics more responsibly and effectively?</li>\n",
    "<li>Whose responsibility is it that online platforms use better metrics? You as the data scientist, the company leadership, the governmental branch that regulates these industries, some third party organization, or the consumer who should be able to control how they spend their time and what content they share?</li>\n",
    "</ol>\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "YOUR ANSWERS HERE\n",
    "\n",
    "1.Using engagement as the main metric to build an online platforms is not inherently unethical, but could be problematic. \n",
    "The engagement metrics are important for the platform to understand the users' interest so that the platform can improve the users experience, which is good for platform since more consumers coming in and potentially increases the revenue. However, if we only look on engagement without considering the quality of the content can lead to the spread of the explicit content, disinformation or harmful content. Moreover, it could lead to addictive behaviors and mental health issues. \n",
    "\n",
    "2. We do have diverse metrics. Other than engagement, we can use a 5 degree metrics to measure the content quality like user satisfaction or misinformation rates. In addition, instead of looking at the immediate engagement, we can evaluate how the content affects users over time. Moreover, the platform can be more transparent and allow the users to understand why they are seeing certain content. Metrics can also be designed to asses the impact of content on users' mental health. \n",
    "\n",
    "3. Data scientist, the company leadership, the governmental branch that regulates these industries, some third party organization, and the consumers should all be responsible for a better use of metrics. Data scientist have a responsibility to develop and propose metrics that are ethically sound. Company Leadership should prioritize responsible metrics that balance business goals with user well-being. Government can play a role in setting standards and guidelines to ensure that online platforms operate responsibly. Third-Party Organizations can audit and compare with baseline of companies to see if model is drifting without biases. Consumers should be informed how engagement metrics influence their experience and content."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.3 -- Individual responsibilities\n",
    "rubric={reasoning:100}\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    " \n",
    "<ol type=\"1\">\n",
    "<li>Do you think it is OK to share an article after just reading the headline but not the entire content? Does it matter what topic the article is about?</li>\n",
    "<li>Describe a few technological and personal solutions that you think would help reduce spread of disinformation?</li>\n",
    "<li><p>In the questions above we mostly discussed how social media company's could stop spreading disinformation, but what about your responsibility as a consumer of this information? Shouldn't you be able to select what are credible sources and avoid being tricked into clicking and sharing disinformation?</p></li>\n",
    "</ol>\n",
    " \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. No, it is not alright to do so. Particularly in the current media landscape, where clickbait is rife and consumers are incentivised to scroll quickly past articles and posts which do not immediately stand out to them, the primary purpose of headlines is arguably to grab attention, whatever the cost. As such, producers of online articles are also incentivised to make headlines which invite engagement but might be misleading, and the contents of an article might not always match the headline. Consumers like us thus need to be careful and should read articles in full before sharing them.\n",
    "\n",
    "Individual consumers should take responsibility for their part in propagating fake news, as consumers play a critical part in driving engagement. Their behaviour in online spaces, such as sharing articles, are ultimately the proxies used by online platforms to determine which types of content to promote or restrict, and irresponsible behaviour like sharing articles before reading their contents will skew the online experience for not only the consumers themselves, but also for others who use the platform. This might lead to the spreading of both disinformation and misinformation, not only to their own followers or friends, but with the effects also potentially rippling down to a larger group of users, as the shared article might be interpreted to be 'good' by the algorithm and shared to others outside the individual's social circle. We feel that it does not matter what the topic of the article is, but that it is particularly important to be careful when sharing political articles since fake news tends to thrive in this area, since it often incites very emotional and potentially harmful reactions, and might also have severe impacts on global events, such as elections.\n",
    "\n",
    "One caveat to this is that we cannot expect everyone to be media literate, since not everyone has access to resources on digital or media literacy. Thus, it may be argued that this standard of responsibility should not be applied to all consumers utilising online platforms. However, instead of weakening individuals' responsibility for exercising, we feel that this strengthens the need for consumers who are indeed digitally literate, and thus should know better, to be even more responsible in being on guard against fake news, such as by reading articles in full before sharing them.\n",
    "\n",
    "2. We have a few suggestions, as follows: <br>\n",
    "\n",
    "**Personal Solutions** \n",
    "- As discussed above, consumers should be aware of potential signs of fake news to look out for, and should be mindful of their online behaviours, like deciding on what to share.\n",
    "- Consumers should carry out fact checking before sharing or engaging meaningfully with articles.\n",
    "- Consumers should check the sources of articles and news before sharing them. Creators should also cite their sources.\n",
    "- Awareness programs to share about digital literacy skills should be set up, and individuals should also play a role in educating their friends and family members who might not have these skills, like older family members who are not used to using ionline platforms.\n",
    "\n",
    "**Technological Solutions** <br>\n",
    "Our group has thought of a few solutions which utilise technology to combat the propagation of disinformation. In all these solutions, we would like to emphasise the importance of human involvement - we believe that even when technology is used, humans should always be involved in the implementation of these solutions, as we feel that at this point, humans are ultimately better able to screen for disinformation than machines, since they are aware of cultural and political contexts which purely technological tools might miss out on in their screening. This also adds transparency and explanability to decisions made by online platforms, which we feel is desirable and more fair. We do recognise that humans are also fallible, since humans have political biases which might cause them to flag some types of news as fake news more than other types of news, but we feel that at this point, humans are still the best solution. We would also like to propose that perhaps a group of diverse human moderators could be used to hopefully average out biases and mitigate this.\n",
    "- A sentiment analyser could be used to screen if articles or other forms of content contain or aim to incite extreme emotions, which would have negative effects on consumers and are a flag for potential disinformation. Content which does not pass this initial screening should be put on hold and passed to human moderators, who check\n",
    "- Likes and dislikes can be one form users can use to indicate whether an article/form of content is 'good' or not, and might be an indicator of whether the content incites emotional responses, which is common in posts used in disinformation campaigns. Tools can hence be used to flag content which is heavily liked or disliked, which should raise suspicion, and these forms of content could be temporarily restricted. Human moderators should check these articles and other forms of content before choosing to delete them or lift the  restrictions.\n",
    "    - On this note, taking inspiration from Kaggle's implementation of tracking upvotes, other metrics like the rate and consistency of likes/dislikes could be tracked, as sudden bursts of likes or dislikes might indicate collusion, or concerted efforts to boost or dampen the spread of articles, which might indicate that a disinformation campaign is under way.\n",
    "- Information on the likes and dislikes certain posts/articles/other forms of content receive should be made transparent to consumers, such as by having an optional panel consumers can open to view more information on the engagement posts have received. This includes not only the number of likes and dislikes but also other information about the engagement posts receive, particularly the ratio of likes to dislikes and the time taken to like/dislike a video. This is as very quick likes and dislikes are suspicious, and this additional information might help consumers to deduce whether the likes/dislikes were organic or not, and thus make a decision on what they think of the quality of information in the content.\n",
    "- Companies should punish people who share disinformation, such as by banning accounts which spread disinformation.\n",
    "\n",
    "3. We are also responsible. Not everyone can detect but those who can detect should be more responsible. Education campaigns important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.4 (Challenging)\n",
    "rubric={reasoning:20}\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "Read <a href=https://themarkup.org/show-your-work/2021/11/18/how-we-investigated-facebooks-most-popular-content> this article on the use of metrics to promote content at Facebook</a>.\n",
    "\n",
    "<ol>\n",
    "<li>Summarize the article in 3-4 sentences to demonstrate your understanding of their main findings.</li>\n",
    "<li>Write a short paragraph about what you think about the analysis and how it was conducted. Does it seem like a reasonable way of measuring what the authors claim that they are measuring?</li>\n",
    "<li>When investigating issues (ethical or otherwise), it is important that we go beyond what is immediately presented to us in a single article. <a href=https://themarkup.org/citizen-browser/2021/01/05/how-we-built-a-facebook-inspector> Find out more about the citizen panel</a>. Is there anything there that changes your interpretation of the results? Why/Why not?</li>\n",
    "</ol>\n",
    "\n",
    "<a href=https://github.com/the-markup/facebook-report-verification>More info about the report here</a> if you are interested, but it is not required to answer the question. \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR ANSWERS HERE\n",
    "\n",
    "1.\n",
    "\n",
    "2.\n",
    "\n",
    "3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "feedback"
    ]
   },
   "source": [
    "---\n",
    "\n",
    "# Help us improve the labs\n",
    "\n",
    "The MDS program is continually looking to improve our courses, including lab questions and content. The following optional questions will not affect your grade in any way nor will they be used for anything other than program improvement:\n",
    "\n",
    "1. Approximately how many hours did you spend working or thinking about this assignment (including lab time)?\n",
    "\n",
    "#Ans:\n",
    "\n",
    "2. Were there any questions that you particularly liked or disliked?\n",
    "\n",
    "#Ans: [Questions you liked]\n",
    "\n",
    "#Ans: [Questions you disliked]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "b98692558f58bef945e1a53707f9e7cae3bda69fed90edc0c37d8470acb8e49e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
